{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>186.0000</td>\n",
       "      <td>275.0000</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>243.0000</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    radius_mean   texture_mean   perimeter_mean   area_mean   smoothness_mean  \\\n",
       "0         17.99          10.38            122.8      1001.0           0.11840   \n",
       "1         20.57          17.77            132.9      1326.0           0.08474   \n",
       "2         19.69          21.25            130.0      1203.0           0.10960   \n",
       "\n",
       "    compactness_mean   concavity_mean  concave_points_mean   symmetry_mean  \\\n",
       "0            0.27760           0.3001              0.14710          0.2419   \n",
       "1            0.07864           0.0869              0.07017          0.1812   \n",
       "2            0.15990           0.1974              0.12790          0.2069   \n",
       "\n",
       "    fractal_dimension_mean  ...   radius_worst   texture_worst  \\\n",
       "0                  0.07871  ...          25.38           17.33   \n",
       "1                  0.05667  ...          24.99           23.41   \n",
       "2                  0.05999  ...          23.57           25.53   \n",
       "\n",
       "    perimeter_worst   area_worst   smoothness_worst   compactness_worst  \\\n",
       "0             184.6       2019.0             0.1622              0.6656   \n",
       "1             158.8       1956.0             0.1238              0.1866   \n",
       "2             152.5       1709.0             0.1444              0.4245   \n",
       "\n",
       "    concavity_worst   concave_points_worst   symmetry_worst  \\\n",
       "0            0.7119                 0.2654           0.4601   \n",
       "1            0.2416               186.0000         275.0000   \n",
       "2            0.4504               243.0000           0.3613   \n",
       "\n",
       "    fractal_dimension_worst  \n",
       "0                   0.11890  \n",
       "1                   0.08902  \n",
       "2                   0.08758  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsores = pd.read_csv(\"entradas-breast.csv\")\n",
    "previsores.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  0\n",
       "2  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = pd.read_csv(\"saidas-breast.csv\")\n",
    "classes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_train, previsores_test, classes_train, classes_test = train_test_split(previsores, classes, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBERVAÇÃO SOBRE KERAS\n",
    "\n",
    "##  Sequential - Classe para criação da rede neural, chamado assim pois tem aquela sequência: camada de entrada, camada oculta(ou várias camadas ocultas), e a camada de saída.\n",
    "\n",
    "## Dense - Classe que utiliza camadas densas na rede neural, significa que cada um dos neuronios e ligado com todos os outros da camada subsequente. Também chamado de \"Neural Fully Connect\", ou seja, a conexão total entre neurônios.\n",
    "\n",
    "\n",
    "## Cria nova rede neural\n",
    "classificador = Sequential() \n",
    "\n",
    "## Adicionando nova camada oculta\n",
    "classificador.add(...)\n",
    "\n",
    "# Parâmetros dentro da camada oculta\n",
    "## units - Quantos neurônios farão parte da minha camada oculta, utilizando uma fórmula, usando o número de entradas somando o numero de neuronios na camada de saída. Somando entradas e saidas e divide por 2. Formula deve ser utilizada como primeiro teste para depois ir especulando(diminuindo ou aumentando) enquanto monitora os resultados.\n",
    "\n",
    "## activation - função de ativação, nesse caso é o 'relu', para projetos de deep learning tende a dar resultados melhores.\n",
    "\n",
    "## kernel_initializer - 'random', pesos iniciam de forma aleatória por padrão.\n",
    "\n",
    "## input_dim - Quantos elementos existem na camada de entrada, como tem-se 30 features, serão 30 neuronios na camada de entrada. Só coloca este parametro para a primeira camada oculta, pois dentro da primeira camada oculta que se insere e configura a camada de entrada.\n",
    "\n",
    "# Camada de Saída\n",
    "## classificador.add(Dense( units=1, activation = 'sigmoid')) - Um neuronio só, pois no exemplo ele tem uma resposta, no caso se o cancer será maligno ou benigno, e a função de ativação é 'sigmoid' pois ele retorna o valor entre 0 e 1, como se fosse a probabilidade de um evento acontecer, nesse caso do cancer ser maligno ou benigno.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform', input_dim=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classificador.compile(. . .) \n",
    "\n",
    "## optimizer - Qual é a função que irá ser utilizado para ajustes dos pesos, aqui entra a parte da descida do gradiente ou da descida do gradiente estocastico, por padrão irá ser utilizado o 'adam' que é uma otimização da descida do gradiente estocastico. Sugere-se sempre começar com 'adam' e caso os resultados não sejam tão bons pode-se testar outros tipos de otimizadores, porém esse é o mais indicado e o que melhor se adapta a maioria dos casos. SGD é o otimizador mais classico de todos, por exemplo. RMSprop, muito usado para RNN.\n",
    "\n",
    "## loss - é a função de perda, maneira que irá fazer o calculo do erro, como no exemplo é um problema de classificação binaria, irá ser utilizado 'binary_crossentropy'.  Entre os tipos, tem-se os mais conhecidos como: mse(mean_squared_error), rmse(root_mean_squared_error) e etc. Utiliza-se o 'categorical_crossentropy quando estiver trabalhando com mais de duas classes. É recomendado utilizar o crossentropy porque a fórmula que é utilizada para fazer o calculo do erro leva em consideração o logaritimo, então ele vai considerar a probabilidade que terá de um modelo logistico, como por exemplo uma regressão logistica, ele vai ter uma penalização maior quando houver uma classificação errada. \n",
    "\n",
    "## metrics - qual métrica para fazer a avaliação, formado de vetor[ ] , pode-se usar mais de uma métrica, nesse caso será 'binary_accuracy' que é a ideia de pegar quantos registros foram classificados certos e quantos errados, divide os registros classificados corretamente pelo total. 'binary_accuracy' justamente pelo fato de estar trabalhando com um problema de classificação de somente duas classes. É importanta saber a caracteristica do teu problema e com base nisso saberá com quais parametros preencher a rede neural. Tem outras metricas como 'categorical_accuracy'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classificador.fit(x_train, y_train, batch_size, epochs) \n",
    "\n",
    "## batch_size - Ele calcula o erro para o número informado aqui para estão calcular os pesos.\n",
    "\n",
    "## epochs - Quantas vezes será feito o ajuste dos pesos, todo o processo foward e back propagation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "426/426 [==============================] - 0s 438us/step - loss: 5.2414 - binary_accuracy: 0.6432\n",
      "Epoch 2/100\n",
      "426/426 [==============================] - 0s 101us/step - loss: 4.8755 - binary_accuracy: 0.6737\n",
      "Epoch 3/100\n",
      "426/426 [==============================] - 0s 98us/step - loss: 4.7865 - binary_accuracy: 0.6854\n",
      "Epoch 4/100\n",
      "426/426 [==============================] - 0s 113us/step - loss: 4.8156 - binary_accuracy: 0.6502\n",
      "Epoch 5/100\n",
      "426/426 [==============================] - 0s 114us/step - loss: 5.4232 - binary_accuracy: 0.6291\n",
      "Epoch 6/100\n",
      "426/426 [==============================] - 0s 102us/step - loss: 4.9624 - binary_accuracy: 0.6690\n",
      "Epoch 7/100\n",
      "426/426 [==============================] - 0s 96us/step - loss: 4.8184 - binary_accuracy: 0.6549\n",
      "Epoch 8/100\n",
      "426/426 [==============================] - 0s 87us/step - loss: 3.7655 - binary_accuracy: 0.6995\n",
      "Epoch 9/100\n",
      "426/426 [==============================] - 0s 115us/step - loss: 3.5115 - binary_accuracy: 0.7277\n",
      "Epoch 10/100\n",
      "426/426 [==============================] - 0s 86us/step - loss: 3.1187 - binary_accuracy: 0.7441\n",
      "Epoch 11/100\n",
      "426/426 [==============================] - 0s 99us/step - loss: 1.6182 - binary_accuracy: 0.8427\n",
      "Epoch 12/100\n",
      "426/426 [==============================] - 0s 90us/step - loss: 0.9520 - binary_accuracy: 0.8732\n",
      "Epoch 13/100\n",
      "426/426 [==============================] - 0s 89us/step - loss: 0.7896 - binary_accuracy: 0.8991\n",
      "Epoch 14/100\n",
      "426/426 [==============================] - 0s 106us/step - loss: 0.6859 - binary_accuracy: 0.9155\n",
      "Epoch 15/100\n",
      "426/426 [==============================] - 0s 117us/step - loss: 1.4360 - binary_accuracy: 0.8380\n",
      "Epoch 16/100\n",
      "426/426 [==============================] - 0s 99us/step - loss: 1.1730 - binary_accuracy: 0.8615\n",
      "Epoch 17/100\n",
      "426/426 [==============================] - 0s 94us/step - loss: 1.1656 - binary_accuracy: 0.8521\n",
      "Epoch 18/100\n",
      "426/426 [==============================] - 0s 113us/step - loss: 1.0502 - binary_accuracy: 0.8615\n",
      "Epoch 19/100\n",
      "426/426 [==============================] - 0s 113us/step - loss: 1.4654 - binary_accuracy: 0.8498\n",
      "Epoch 20/100\n",
      "426/426 [==============================] - 0s 114us/step - loss: 0.8520 - binary_accuracy: 0.8779\n",
      "Epoch 21/100\n",
      "426/426 [==============================] - 0s 91us/step - loss: 1.0789 - binary_accuracy: 0.8545\n",
      "Epoch 22/100\n",
      "426/426 [==============================] - 0s 99us/step - loss: 0.8506 - binary_accuracy: 0.8991\n",
      "Epoch 23/100\n",
      "426/426 [==============================] - 0s 113us/step - loss: 0.5855 - binary_accuracy: 0.9085\n",
      "Epoch 24/100\n",
      "426/426 [==============================] - 0s 326us/step - loss: 0.5476 - binary_accuracy: 0.9178\n",
      "Epoch 25/100\n",
      "426/426 [==============================] - 0s 239us/step - loss: 0.6302 - binary_accuracy: 0.9061\n",
      "Epoch 26/100\n",
      "426/426 [==============================] - 0s 166us/step - loss: 0.5873 - binary_accuracy: 0.8850\n",
      "Epoch 27/100\n",
      "426/426 [==============================] - 0s 326us/step - loss: 0.9202 - binary_accuracy: 0.8545\n",
      "Epoch 28/100\n",
      "426/426 [==============================] - 0s 141us/step - loss: 0.6554 - binary_accuracy: 0.9131\n",
      "Epoch 29/100\n",
      "426/426 [==============================] - 0s 128us/step - loss: 0.8384 - binary_accuracy: 0.9108\n",
      "Epoch 30/100\n",
      "426/426 [==============================] - 0s 112us/step - loss: 0.6564 - binary_accuracy: 0.8944\n",
      "Epoch 31/100\n",
      "426/426 [==============================] - 0s 140us/step - loss: 0.7653 - binary_accuracy: 0.8897\n",
      "Epoch 32/100\n",
      "426/426 [==============================] - 0s 102us/step - loss: 0.7683 - binary_accuracy: 0.8756\n",
      "Epoch 33/100\n",
      "426/426 [==============================] - 0s 105us/step - loss: 0.5989 - binary_accuracy: 0.9131\n",
      "Epoch 34/100\n",
      "426/426 [==============================] - 0s 100us/step - loss: 1.0852 - binary_accuracy: 0.8638\n",
      "Epoch 35/100\n",
      "426/426 [==============================] - 0s 112us/step - loss: 0.8188 - binary_accuracy: 0.8850\n",
      "Epoch 36/100\n",
      "426/426 [==============================] - 0s 107us/step - loss: 0.6547 - binary_accuracy: 0.8920\n",
      "Epoch 37/100\n",
      "426/426 [==============================] - 0s 111us/step - loss: 0.6869 - binary_accuracy: 0.8897\n",
      "Epoch 38/100\n",
      "426/426 [==============================] - 0s 108us/step - loss: 0.4744 - binary_accuracy: 0.9155\n",
      "Epoch 39/100\n",
      "426/426 [==============================] - 0s 118us/step - loss: 0.5618 - binary_accuracy: 0.9038\n",
      "Epoch 40/100\n",
      "426/426 [==============================] - 0s 117us/step - loss: 0.3466 - binary_accuracy: 0.9366\n",
      "Epoch 41/100\n",
      "426/426 [==============================] - 0s 143us/step - loss: 1.0548 - binary_accuracy: 0.8709\n",
      "Epoch 42/100\n",
      "426/426 [==============================] - 0s 155us/step - loss: 0.4531 - binary_accuracy: 0.9178\n",
      "Epoch 43/100\n",
      "426/426 [==============================] - 0s 154us/step - loss: 0.9262 - binary_accuracy: 0.8779\n",
      "Epoch 44/100\n",
      "426/426 [==============================] - 0s 178us/step - loss: 0.8278 - binary_accuracy: 0.8897\n",
      "Epoch 45/100\n",
      "426/426 [==============================] - 0s 120us/step - loss: 0.5750 - binary_accuracy: 0.8991\n",
      "Epoch 46/100\n",
      "426/426 [==============================] - 0s 107us/step - loss: 0.5109 - binary_accuracy: 0.9178\n",
      "Epoch 47/100\n",
      "426/426 [==============================] - 0s 162us/step - loss: 0.3180 - binary_accuracy: 0.9484\n",
      "Epoch 48/100\n",
      "426/426 [==============================] - 0s 163us/step - loss: 0.5430 - binary_accuracy: 0.9131\n",
      "Epoch 49/100\n",
      "426/426 [==============================] - 0s 190us/step - loss: 0.6185 - binary_accuracy: 0.9061\n",
      "Epoch 50/100\n",
      "426/426 [==============================] - 0s 144us/step - loss: 0.8023 - binary_accuracy: 0.8873\n",
      "Epoch 51/100\n",
      "426/426 [==============================] - 0s 120us/step - loss: 0.4622 - binary_accuracy: 0.9225\n",
      "Epoch 52/100\n",
      "426/426 [==============================] - 0s 117us/step - loss: 0.3827 - binary_accuracy: 0.9390\n",
      "Epoch 53/100\n",
      "426/426 [==============================] - 0s 95us/step - loss: 0.4369 - binary_accuracy: 0.9202\n",
      "Epoch 54/100\n",
      "426/426 [==============================] - 0s 132us/step - loss: 0.3684 - binary_accuracy: 0.9343\n",
      "Epoch 55/100\n",
      "426/426 [==============================] - 0s 143us/step - loss: 0.3871 - binary_accuracy: 0.9366\n",
      "Epoch 56/100\n",
      "426/426 [==============================] - 0s 122us/step - loss: 0.7611 - binary_accuracy: 0.8873\n",
      "Epoch 57/100\n",
      "426/426 [==============================] - 0s 134us/step - loss: 0.5824 - binary_accuracy: 0.9108\n",
      "Epoch 58/100\n",
      "426/426 [==============================] - 0s 107us/step - loss: 0.3692 - binary_accuracy: 0.9390\n",
      "Epoch 59/100\n",
      "426/426 [==============================] - 0s 98us/step - loss: 0.7472 - binary_accuracy: 0.9061\n",
      "Epoch 60/100\n",
      "426/426 [==============================] - 0s 169us/step - loss: 0.5171 - binary_accuracy: 0.9131\n",
      "Epoch 61/100\n",
      "426/426 [==============================] - 0s 176us/step - loss: 0.4589 - binary_accuracy: 0.9178\n",
      "Epoch 62/100\n",
      "426/426 [==============================] - 0s 141us/step - loss: 1.7206 - binary_accuracy: 0.8216\n",
      "Epoch 63/100\n",
      "426/426 [==============================] - 0s 95us/step - loss: 1.5820 - binary_accuracy: 0.8568\n",
      "Epoch 64/100\n",
      "426/426 [==============================] - 0s 107us/step - loss: 0.4658 - binary_accuracy: 0.9296\n",
      "Epoch 65/100\n",
      "426/426 [==============================] - 0s 266us/step - loss: 0.4923 - binary_accuracy: 0.9225\n",
      "Epoch 66/100\n",
      "426/426 [==============================] - 0s 363us/step - loss: 0.7289 - binary_accuracy: 0.9061\n",
      "Epoch 67/100\n",
      "426/426 [==============================] - 0s 443us/step - loss: 0.7434 - binary_accuracy: 0.8920\n",
      "Epoch 68/100\n",
      "426/426 [==============================] - 0s 390us/step - loss: 0.4867 - binary_accuracy: 0.9272\n",
      "Epoch 69/100\n",
      "426/426 [==============================] - 0s 382us/step - loss: 0.3266 - binary_accuracy: 0.9413\n",
      "Epoch 70/100\n",
      "426/426 [==============================] - 0s 459us/step - loss: 0.2820 - binary_accuracy: 0.9413\n",
      "Epoch 71/100\n",
      "426/426 [==============================] - 0s 302us/step - loss: 0.3396 - binary_accuracy: 0.9437\n",
      "Epoch 72/100\n",
      "426/426 [==============================] - 0s 185us/step - loss: 0.3293 - binary_accuracy: 0.9343\n",
      "Epoch 73/100\n",
      "426/426 [==============================] - 0s 155us/step - loss: 0.2562 - binary_accuracy: 0.9484\n",
      "Epoch 74/100\n",
      "426/426 [==============================] - 0s 173us/step - loss: 0.3284 - binary_accuracy: 0.9413\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 176us/step - loss: 0.5963 - binary_accuracy: 0.8991\n",
      "Epoch 76/100\n",
      "426/426 [==============================] - 0s 149us/step - loss: 0.4654 - binary_accuracy: 0.9108\n",
      "Epoch 77/100\n",
      "426/426 [==============================] - 0s 100us/step - loss: 0.6225 - binary_accuracy: 0.9155\n",
      "Epoch 78/100\n",
      "426/426 [==============================] - 0s 90us/step - loss: 1.0667 - binary_accuracy: 0.8709\n",
      "Epoch 79/100\n",
      "426/426 [==============================] - 0s 102us/step - loss: 0.3991 - binary_accuracy: 0.9343\n",
      "Epoch 80/100\n",
      "426/426 [==============================] - 0s 136us/step - loss: 0.7301 - binary_accuracy: 0.9038\n",
      "Epoch 81/100\n",
      "426/426 [==============================] - 0s 120us/step - loss: 0.6131 - binary_accuracy: 0.9061\n",
      "Epoch 82/100\n",
      "426/426 [==============================] - 0s 145us/step - loss: 0.6341 - binary_accuracy: 0.9085\n",
      "Epoch 83/100\n",
      "426/426 [==============================] - 0s 114us/step - loss: 0.3137 - binary_accuracy: 0.9343\n",
      "Epoch 84/100\n",
      "426/426 [==============================] - 0s 102us/step - loss: 0.8005 - binary_accuracy: 0.8944\n",
      "Epoch 85/100\n",
      "426/426 [==============================] - 0s 148us/step - loss: 0.4812 - binary_accuracy: 0.9296\n",
      "Epoch 86/100\n",
      "426/426 [==============================] - 0s 142us/step - loss: 0.2870 - binary_accuracy: 0.9460\n",
      "Epoch 87/100\n",
      "426/426 [==============================] - 0s 148us/step - loss: 0.4852 - binary_accuracy: 0.9085\n",
      "Epoch 88/100\n",
      "426/426 [==============================] - 0s 137us/step - loss: 0.5175 - binary_accuracy: 0.9155\n",
      "Epoch 89/100\n",
      "426/426 [==============================] - 0s 102us/step - loss: 0.4876 - binary_accuracy: 0.9319\n",
      "Epoch 90/100\n",
      "426/426 [==============================] - 0s 87us/step - loss: 0.2617 - binary_accuracy: 0.9413\n",
      "Epoch 91/100\n",
      "426/426 [==============================] - 0s 118us/step - loss: 0.3223 - binary_accuracy: 0.9319\n",
      "Epoch 92/100\n",
      "426/426 [==============================] - 0s 147us/step - loss: 0.2661 - binary_accuracy: 0.9296\n",
      "Epoch 93/100\n",
      "426/426 [==============================] - 0s 150us/step - loss: 0.2919 - binary_accuracy: 0.9437\n",
      "Epoch 94/100\n",
      "426/426 [==============================] - 0s 131us/step - loss: 0.2759 - binary_accuracy: 0.9319\n",
      "Epoch 95/100\n",
      "426/426 [==============================] - 0s 104us/step - loss: 0.3372 - binary_accuracy: 0.9272\n",
      "Epoch 96/100\n",
      "426/426 [==============================] - 0s 105us/step - loss: 0.3095 - binary_accuracy: 0.9390\n",
      "Epoch 97/100\n",
      "426/426 [==============================] - 0s 117us/step - loss: 0.5717 - binary_accuracy: 0.9108\n",
      "Epoch 98/100\n",
      "426/426 [==============================] - 0s 152us/step - loss: 0.3985 - binary_accuracy: 0.9390\n",
      "Epoch 99/100\n",
      "426/426 [==============================] - 0s 150us/step - loss: 0.4546 - binary_accuracy: 0.9249\n",
      "Epoch 100/100\n",
      "426/426 [==============================] - 0s 140us/step - loss: 0.5327 - binary_accuracy: 0.9155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f48a412d0b8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.fit(previsores_train, classes_train, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agora é preciso avaliar o modelo com a base de dados de teste para ter uma avaliação correta, pois o resultado acima é feito com em cima da base de dados de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = classificador.predict(previsores_test)\n",
    "previsoes = (previsoes > 0.5) # Como o classificador retorna 'sigmoid' na saida, apresentando porcentagens, aqui considera-se que qualquer valor acima de 0.5 seja True(1), caso contrario False(0). Necessario para avaliar a classificação binaria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score #utilizando recursos do keras para avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8671328671328671"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precisao = accuracy_score(classes_test, previsoes)\n",
    "precisao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27, 18],\n",
       "       [ 1, 97]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz = confusion_matrix(classes_test, previsoes)\n",
    "matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 35us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3010973255117457, 0.8671328679664986]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado = classificador.evaluate(previsores_test, classes_test) # também pode-se usar os recursos do keras para avaliar o modelo, onde ele informa o valor da função de erro e a precisão. Pode usar o recursos tanto do sklearn como do keras.\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>186.0000</td>\n",
       "      <td>275.0000</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>243.0000</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    radius_mean   texture_mean   perimeter_mean   area_mean   smoothness_mean  \\\n",
       "0         17.99          10.38            122.8      1001.0           0.11840   \n",
       "1         20.57          17.77            132.9      1326.0           0.08474   \n",
       "2         19.69          21.25            130.0      1203.0           0.10960   \n",
       "\n",
       "    compactness_mean   concavity_mean  concave_points_mean   symmetry_mean  \\\n",
       "0            0.27760           0.3001              0.14710          0.2419   \n",
       "1            0.07864           0.0869              0.07017          0.1812   \n",
       "2            0.15990           0.1974              0.12790          0.2069   \n",
       "\n",
       "    fractal_dimension_mean  ...   radius_worst   texture_worst  \\\n",
       "0                  0.07871  ...          25.38           17.33   \n",
       "1                  0.05667  ...          24.99           23.41   \n",
       "2                  0.05999  ...          23.57           25.53   \n",
       "\n",
       "    perimeter_worst   area_worst   smoothness_worst   compactness_worst  \\\n",
       "0             184.6       2019.0             0.1622              0.6656   \n",
       "1             158.8       1956.0             0.1238              0.1866   \n",
       "2             152.5       1709.0             0.1444              0.4245   \n",
       "\n",
       "    concavity_worst   concave_points_worst   symmetry_worst  \\\n",
       "0            0.7119                 0.2654           0.4601   \n",
       "1            0.2416               186.0000         275.0000   \n",
       "2            0.4504               243.0000           0.3613   \n",
       "\n",
       "    fractal_dimension_worst  \n",
       "0                   0.11890  \n",
       "1                   0.08902  \n",
       "2                   0.08758  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsores = pd.read_csv(\"entradas-breast.csv\")\n",
    "previsores.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  0\n",
       "2  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = pd.read_csv(\"saidas-breast.csv\")\n",
    "classes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_train, previsores_test, classes_train, classes_test = train_test_split(previsores, classes, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0827 20:28:10.845335 140460704347968 deprecation_wrapper.py:119] From /home/jarbasjr/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classificador = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0827 20:28:10.865236 140460704347968 deprecation_wrapper.py:119] From /home/jarbasjr/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0827 20:28:10.868033 140460704347968 deprecation_wrapper.py:119] From /home/jarbasjr/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform', input_dim=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "otimizador = keras.optimizers.Adam(lr = 0.001, decay=0.0001, clipvalue=0.5) # coloca o otimizador configurado aqui no 'optimizer', fazer testes mundando estes três parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0827 20:28:10.981956 140460704347968 deprecation_wrapper.py:119] From /home/jarbasjr/.local/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0827 20:28:10.989870 140460704347968 deprecation_wrapper.py:119] From /home/jarbasjr/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0827 20:28:10.995506 140460704347968 deprecation.py:323] From /home/jarbasjr/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "classificador.compile(optimizer=otimizador, loss='binary_crossentropy', metrics = ['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0827 20:28:11.153581 140460704347968 deprecation_wrapper.py:119] From /home/jarbasjr/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "426/426 [==============================] - 0s 674us/step - loss: 1.0501 - binary_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "426/426 [==============================] - 0s 104us/step - loss: 0.4920 - binary_accuracy: 0.7746\n",
      "Epoch 3/100\n",
      "426/426 [==============================] - 0s 103us/step - loss: 0.4695 - binary_accuracy: 0.7746\n",
      "Epoch 4/100\n",
      "426/426 [==============================] - 0s 88us/step - loss: 0.6204 - binary_accuracy: 0.7535\n",
      "Epoch 5/100\n",
      "426/426 [==============================] - 0s 107us/step - loss: 0.5153 - binary_accuracy: 0.8216\n",
      "Epoch 6/100\n",
      "426/426 [==============================] - 0s 97us/step - loss: 0.4736 - binary_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "426/426 [==============================] - 0s 87us/step - loss: 0.4073 - binary_accuracy: 0.8474\n",
      "Epoch 8/100\n",
      "426/426 [==============================] - 0s 124us/step - loss: 0.5088 - binary_accuracy: 0.8099\n",
      "Epoch 9/100\n",
      "426/426 [==============================] - 0s 84us/step - loss: 0.4922 - binary_accuracy: 0.8286\n",
      "Epoch 10/100\n",
      "426/426 [==============================] - 0s 106us/step - loss: 0.5098 - binary_accuracy: 0.8263\n",
      "Epoch 11/100\n",
      "426/426 [==============================] - 0s 94us/step - loss: 0.4514 - binary_accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "426/426 [==============================] - 0s 116us/step - loss: 0.6433 - binary_accuracy: 0.7958\n",
      "Epoch 13/100\n",
      "426/426 [==============================] - 0s 145us/step - loss: 0.7355 - binary_accuracy: 0.8192\n",
      "Epoch 14/100\n",
      "426/426 [==============================] - 0s 145us/step - loss: 0.3939 - binary_accuracy: 0.8662\n",
      "Epoch 15/100\n",
      "426/426 [==============================] - 0s 131us/step - loss: 0.4144 - binary_accuracy: 0.8732\n",
      "Epoch 16/100\n",
      "426/426 [==============================] - 0s 117us/step - loss: 0.5318 - binary_accuracy: 0.8357\n",
      "Epoch 17/100\n",
      "426/426 [==============================] - 0s 105us/step - loss: 0.5291 - binary_accuracy: 0.8404\n",
      "Epoch 18/100\n",
      "426/426 [==============================] - 0s 95us/step - loss: 0.5548 - binary_accuracy: 0.8498\n",
      "Epoch 19/100\n",
      "426/426 [==============================] - 0s 114us/step - loss: 0.5123 - binary_accuracy: 0.8427\n",
      "Epoch 20/100\n",
      "426/426 [==============================] - 0s 115us/step - loss: 0.5173 - binary_accuracy: 0.8263\n",
      "Epoch 21/100\n",
      "426/426 [==============================] - 0s 104us/step - loss: 0.6849 - binary_accuracy: 0.7934\n",
      "Epoch 22/100\n",
      "426/426 [==============================] - 0s 104us/step - loss: 0.7461 - binary_accuracy: 0.8498\n",
      "Epoch 23/100\n",
      "426/426 [==============================] - 0s 113us/step - loss: 0.9895 - binary_accuracy: 0.7676\n",
      "Epoch 24/100\n",
      "426/426 [==============================] - 0s 92us/step - loss: 0.6386 - binary_accuracy: 0.8028\n",
      "Epoch 25/100\n",
      "426/426 [==============================] - 0s 152us/step - loss: 0.8982 - binary_accuracy: 0.8052\n",
      "Epoch 26/100\n",
      "426/426 [==============================] - 0s 196us/step - loss: 0.4620 - binary_accuracy: 0.8451\n",
      "Epoch 27/100\n",
      "426/426 [==============================] - 0s 166us/step - loss: 0.4558 - binary_accuracy: 0.8521\n",
      "Epoch 28/100\n",
      "426/426 [==============================] - 0s 119us/step - loss: 0.4516 - binary_accuracy: 0.8756\n",
      "Epoch 29/100\n",
      "426/426 [==============================] - 0s 105us/step - loss: 0.4478 - binary_accuracy: 0.8521\n",
      "Epoch 30/100\n",
      "426/426 [==============================] - 0s 98us/step - loss: 0.4486 - binary_accuracy: 0.8545\n",
      "Epoch 31/100\n",
      "426/426 [==============================] - 0s 193us/step - loss: 0.4164 - binary_accuracy: 0.8638\n",
      "Epoch 32/100\n",
      "426/426 [==============================] - 0s 168us/step - loss: 0.6513 - binary_accuracy: 0.8192\n",
      "Epoch 33/100\n",
      "426/426 [==============================] - 0s 150us/step - loss: 0.6778 - binary_accuracy: 0.8357\n",
      "Epoch 34/100\n",
      "426/426 [==============================] - 0s 104us/step - loss: 0.5316 - binary_accuracy: 0.8521\n",
      "Epoch 35/100\n",
      "426/426 [==============================] - 0s 177us/step - loss: 0.4087 - binary_accuracy: 0.8592\n",
      "Epoch 36/100\n",
      "426/426 [==============================] - 0s 167us/step - loss: 0.5827 - binary_accuracy: 0.8286\n",
      "Epoch 37/100\n",
      "426/426 [==============================] - 0s 192us/step - loss: 0.5636 - binary_accuracy: 0.8451\n",
      "Epoch 38/100\n",
      "426/426 [==============================] - 0s 156us/step - loss: 0.5703 - binary_accuracy: 0.8239\n",
      "Epoch 39/100\n",
      "426/426 [==============================] - 0s 168us/step - loss: 0.4258 - binary_accuracy: 0.8568\n",
      "Epoch 40/100\n",
      "426/426 [==============================] - 0s 167us/step - loss: 0.4959 - binary_accuracy: 0.8263\n",
      "Epoch 41/100\n",
      "426/426 [==============================] - 0s 165us/step - loss: 0.5516 - binary_accuracy: 0.8075\n",
      "Epoch 42/100\n",
      "426/426 [==============================] - 0s 162us/step - loss: 0.4665 - binary_accuracy: 0.8638\n",
      "Epoch 43/100\n",
      "426/426 [==============================] - 0s 189us/step - loss: 0.6774 - binary_accuracy: 0.8169\n",
      "Epoch 44/100\n",
      "426/426 [==============================] - 0s 184us/step - loss: 0.5834 - binary_accuracy: 0.8756\n",
      "Epoch 45/100\n",
      "426/426 [==============================] - 0s 165us/step - loss: 0.4401 - binary_accuracy: 0.8592\n",
      "Epoch 46/100\n",
      "426/426 [==============================] - 0s 207us/step - loss: 0.7056 - binary_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "426/426 [==============================] - 0s 176us/step - loss: 0.3620 - binary_accuracy: 0.8991\n",
      "Epoch 48/100\n",
      "426/426 [==============================] - 0s 178us/step - loss: 0.3557 - binary_accuracy: 0.8732\n",
      "Epoch 49/100\n",
      "426/426 [==============================] - 0s 142us/step - loss: 0.4742 - binary_accuracy: 0.8662\n",
      "Epoch 50/100\n",
      "426/426 [==============================] - 0s 166us/step - loss: 0.6518 - binary_accuracy: 0.8545\n",
      "Epoch 51/100\n",
      "426/426 [==============================] - 0s 132us/step - loss: 0.4124 - binary_accuracy: 0.8709\n",
      "Epoch 52/100\n",
      "426/426 [==============================] - 0s 121us/step - loss: 0.5210 - binary_accuracy: 0.8685\n",
      "Epoch 53/100\n",
      "426/426 [==============================] - 0s 110us/step - loss: 0.6433 - binary_accuracy: 0.8310\n",
      "Epoch 54/100\n",
      "426/426 [==============================] - 0s 116us/step - loss: 0.4351 - binary_accuracy: 0.8756\n",
      "Epoch 55/100\n",
      "426/426 [==============================] - 0s 107us/step - loss: 0.4465 - binary_accuracy: 0.8897\n",
      "Epoch 56/100\n",
      "426/426 [==============================] - 0s 111us/step - loss: 0.5942 - binary_accuracy: 0.8709\n",
      "Epoch 57/100\n",
      "426/426 [==============================] - 0s 96us/step - loss: 0.5454 - binary_accuracy: 0.8498\n",
      "Epoch 58/100\n",
      "426/426 [==============================] - 0s 146us/step - loss: 0.4601 - binary_accuracy: 0.8638\n",
      "Epoch 59/100\n",
      "426/426 [==============================] - 0s 95us/step - loss: 0.4716 - binary_accuracy: 0.8568\n",
      "Epoch 60/100\n",
      "426/426 [==============================] - 0s 97us/step - loss: 0.5090 - binary_accuracy: 0.8568\n",
      "Epoch 61/100\n",
      "426/426 [==============================] - 0s 109us/step - loss: 0.4821 - binary_accuracy: 0.8592\n",
      "Epoch 62/100\n",
      "426/426 [==============================] - 0s 118us/step - loss: 0.4669 - binary_accuracy: 0.8427\n",
      "Epoch 63/100\n",
      "426/426 [==============================] - 0s 129us/step - loss: 0.5494 - binary_accuracy: 0.8521\n",
      "Epoch 64/100\n",
      "426/426 [==============================] - 0s 142us/step - loss: 0.6594 - binary_accuracy: 0.8521\n",
      "Epoch 65/100\n",
      "426/426 [==============================] - 0s 96us/step - loss: 0.5330 - binary_accuracy: 0.8709\n",
      "Epoch 66/100\n",
      "426/426 [==============================] - 0s 129us/step - loss: 0.5578 - binary_accuracy: 0.8662\n",
      "Epoch 67/100\n",
      "426/426 [==============================] - 0s 102us/step - loss: 1.0871 - binary_accuracy: 0.7911\n",
      "Epoch 68/100\n",
      "426/426 [==============================] - 0s 114us/step - loss: 0.4724 - binary_accuracy: 0.8662\n",
      "Epoch 69/100\n",
      "426/426 [==============================] - 0s 104us/step - loss: 0.4131 - binary_accuracy: 0.8944\n",
      "Epoch 70/100\n",
      "426/426 [==============================] - 0s 116us/step - loss: 0.5308 - binary_accuracy: 0.8662\n",
      "Epoch 71/100\n",
      "426/426 [==============================] - 0s 130us/step - loss: 0.5728 - binary_accuracy: 0.8826\n",
      "Epoch 72/100\n",
      "426/426 [==============================] - 0s 129us/step - loss: 0.5140 - binary_accuracy: 0.8873\n",
      "Epoch 73/100\n",
      "426/426 [==============================] - 0s 98us/step - loss: 0.4873 - binary_accuracy: 0.8685\n",
      "Epoch 74/100\n",
      "426/426 [==============================] - 0s 110us/step - loss: 0.6933 - binary_accuracy: 0.8545\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 158us/step - loss: 0.7281 - binary_accuracy: 0.8474\n",
      "Epoch 76/100\n",
      "426/426 [==============================] - 0s 121us/step - loss: 0.7304 - binary_accuracy: 0.8545\n",
      "Epoch 77/100\n",
      "426/426 [==============================] - 0s 105us/step - loss: 0.7014 - binary_accuracy: 0.8662\n",
      "Epoch 78/100\n",
      "426/426 [==============================] - 0s 102us/step - loss: 0.5253 - binary_accuracy: 0.8685\n",
      "Epoch 79/100\n",
      "426/426 [==============================] - 0s 110us/step - loss: 0.5377 - binary_accuracy: 0.8545\n",
      "Epoch 80/100\n",
      "426/426 [==============================] - 0s 84us/step - loss: 0.4698 - binary_accuracy: 0.8850\n",
      "Epoch 81/100\n",
      "426/426 [==============================] - 0s 109us/step - loss: 0.4667 - binary_accuracy: 0.8685\n",
      "Epoch 82/100\n",
      "426/426 [==============================] - 0s 87us/step - loss: 0.5256 - binary_accuracy: 0.8732\n",
      "Epoch 83/100\n",
      "426/426 [==============================] - 0s 114us/step - loss: 0.5266 - binary_accuracy: 0.8638\n",
      "Epoch 84/100\n",
      "426/426 [==============================] - 0s 85us/step - loss: 0.6137 - binary_accuracy: 0.8638\n",
      "Epoch 85/100\n",
      "426/426 [==============================] - 0s 101us/step - loss: 0.5731 - binary_accuracy: 0.8685\n",
      "Epoch 86/100\n",
      "426/426 [==============================] - 0s 99us/step - loss: 0.5465 - binary_accuracy: 0.8685\n",
      "Epoch 87/100\n",
      "426/426 [==============================] - 0s 98us/step - loss: 0.6139 - binary_accuracy: 0.8592\n",
      "Epoch 88/100\n",
      "426/426 [==============================] - 0s 86us/step - loss: 0.5308 - binary_accuracy: 0.8756\n",
      "Epoch 89/100\n",
      "426/426 [==============================] - 0s 103us/step - loss: 0.6334 - binary_accuracy: 0.8592\n",
      "Epoch 90/100\n",
      "426/426 [==============================] - 0s 86us/step - loss: 0.6577 - binary_accuracy: 0.8662\n",
      "Epoch 91/100\n",
      "426/426 [==============================] - 0s 105us/step - loss: 0.5993 - binary_accuracy: 0.8662\n",
      "Epoch 92/100\n",
      "426/426 [==============================] - 0s 100us/step - loss: 0.8029 - binary_accuracy: 0.8709\n",
      "Epoch 93/100\n",
      "426/426 [==============================] - 0s 110us/step - loss: 0.8889 - binary_accuracy: 0.8263\n",
      "Epoch 94/100\n",
      "426/426 [==============================] - 0s 97us/step - loss: 0.7076 - binary_accuracy: 0.8732\n",
      "Epoch 95/100\n",
      "426/426 [==============================] - 0s 96us/step - loss: 0.8221 - binary_accuracy: 0.8357\n",
      "Epoch 96/100\n",
      "426/426 [==============================] - 0s 103us/step - loss: 0.7965 - binary_accuracy: 0.8545\n",
      "Epoch 97/100\n",
      "426/426 [==============================] - 0s 95us/step - loss: 0.9840 - binary_accuracy: 0.8474\n",
      "Epoch 98/100\n",
      "426/426 [==============================] - 0s 120us/step - loss: 0.7927 - binary_accuracy: 0.8216\n",
      "Epoch 99/100\n",
      "426/426 [==============================] - 0s 101us/step - loss: 0.6683 - binary_accuracy: 0.8592\n",
      "Epoch 100/100\n",
      "426/426 [==============================] - 0s 86us/step - loss: 0.8202 - binary_accuracy: 0.8427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbf34a4b828>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.fit(previsores_train, classes_train, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualização dos pesos\n",
    "\n",
    "## O resultado final, o que ela utiliza para classificar novos registros. \n",
    "## No nosso exemplo são as camadas ocultas logo layers[0] e layers[1], entre três partes de peso.\n",
    "## A nossa variavel tem dois elementos,para peso0, layers[0], o primeiro é de tamanho (30,16), referente a camada de entrada que é igual ao numero de tamanhos(30) e ao tamanho da primeira camada oculta(16), logo representando todas os pesos que ligam completamente a camada de entrada a primeira camada oculta.\n",
    "## No peso0 em layers[1] tem (16, ) se refera a camada de bias, que como padrão da classe Dense é use_bias=True, então um neuronio a mais que e ligado em todos os neuronios da camada oculta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-1.60216197e-01,  6.15789518e-02,  1.58756226e-01,\n",
      "         2.48063847e-01, -1.94768146e-01, -1.48448914e-01,\n",
      "        -4.94532026e-02, -2.23904103e-01, -4.17246997e-01,\n",
      "        -3.52100223e-01,  1.31096572e-01, -3.94767284e-01,\n",
      "         1.67148426e-01, -6.69332817e-02,  3.51773687e-02,\n",
      "         1.35188997e-02],\n",
      "       [-1.01877332e-01,  1.36886328e-01,  1.10656768e-01,\n",
      "         2.52837420e-01, -2.61376709e-01,  5.98951913e-02,\n",
      "         7.89564550e-02, -2.89430201e-01, -3.88561159e-01,\n",
      "        -1.96345299e-01, -1.17945438e-02, -3.28271091e-01,\n",
      "         1.50448158e-01, -1.61786769e-02, -2.01044574e-01,\n",
      "        -1.79914355e-01],\n",
      "       [-5.73952049e-02,  3.75879928e-02,  1.93506926e-02,\n",
      "         1.64284959e-01,  6.14291839e-02, -1.11700960e-01,\n",
      "        -6.19973913e-02, -1.67779416e-01, -1.26104265e-01,\n",
      "         1.26929581e-01, -5.16113900e-02, -2.98118472e-01,\n",
      "         2.53897179e-02, -1.24518126e-02, -2.14884989e-03,\n",
      "        -4.24853526e-03],\n",
      "       [ 5.53983971e-02, -6.31913394e-02,  3.31052318e-02,\n",
      "        -7.60043487e-02,  1.61667526e-01,  4.33189310e-02,\n",
      "         1.21927289e-02,  1.19973108e-01,  2.18214095e-02,\n",
      "         1.31742239e-01, -5.36041111e-02,  3.67783494e-02,\n",
      "        -6.36192132e-03, -4.31294069e-02,  2.34356597e-02,\n",
      "         3.25652398e-02],\n",
      "       [-4.42971941e-05,  1.59513846e-01,  3.65256459e-01,\n",
      "        -2.11855937e-02, -9.98945162e-02,  9.44366902e-02,\n",
      "         7.28926584e-02, -1.38167277e-01, -3.51078451e-01,\n",
      "        -3.46146643e-01,  1.23942047e-01, -3.85487348e-01,\n",
      "         2.30234206e-01, -1.26481205e-02, -5.05469274e-03,\n",
      "        -1.04025871e-01],\n",
      "       [-1.99289471e-02, -1.66406780e-02, -5.64495753e-03,\n",
      "         2.64773160e-01,  1.59733947e-02,  3.26581225e-02,\n",
      "        -2.55308971e-02,  1.20551782e-02,  6.01865053e-02,\n",
      "         2.81061381e-02,  2.80524828e-02, -5.49787879e-01,\n",
      "         1.40968844e-01, -5.17442673e-02, -1.72986090e-02,\n",
      "         9.93301868e-02],\n",
      "       [-7.16426224e-02,  5.66489138e-02,  7.98934773e-02,\n",
      "         6.22278303e-02, -6.95168134e-03, -3.09633669e-02,\n",
      "         4.34631528e-03, -1.07307509e-01, -6.19538166e-02,\n",
      "        -8.85909721e-02,  2.96453889e-02, -8.15140456e-02,\n",
      "         7.87851214e-02, -5.73471375e-02,  1.04249738e-01,\n",
      "         2.81932950e-02],\n",
      "       [-6.17383011e-02, -7.86547810e-02,  8.05283114e-02,\n",
      "         1.68708358e-02,  1.24382742e-01, -2.04678439e-02,\n",
      "        -6.14720881e-02, -1.35487348e-01, -7.35748336e-02,\n",
      "        -1.87375874e-03,  2.01690510e-01, -2.23755017e-01,\n",
      "        -2.18069181e-02,  3.76592204e-02,  1.58823699e-01,\n",
      "         1.76855281e-01],\n",
      "       [-1.02662593e-01, -1.03974221e-02, -4.25988324e-02,\n",
      "        -4.09866683e-02,  5.24266101e-02, -1.08292989e-01,\n",
      "         1.61716685e-01,  2.70485222e-01, -1.52999014e-01,\n",
      "         1.01414479e-01,  2.95726117e-02,  1.05962478e-01,\n",
      "        -2.02208698e-01, -6.77084401e-02, -1.46803334e-01,\n",
      "         2.61613466e-02],\n",
      "       [ 5.44957444e-02, -5.79916351e-02, -1.82521343e-01,\n",
      "        -3.90227176e-02,  1.66107059e-01, -1.43466249e-01,\n",
      "        -6.22082800e-02,  2.60053486e-01,  1.60875574e-01,\n",
      "         3.17719340e-01, -4.13044542e-03,  1.11993223e-01,\n",
      "        -2.18568951e-01,  2.81654485e-02,  1.04383290e-01,\n",
      "         2.48843748e-02],\n",
      "       [-7.51672313e-02,  1.12454876e-01,  4.38495055e-02,\n",
      "         6.44052699e-02,  6.86921403e-02, -2.67679766e-02,\n",
      "        -1.26656136e-02,  2.18604058e-01, -3.46987963e-01,\n",
      "         1.19026959e-01,  1.37705160e-02, -1.14217915e-01,\n",
      "        -3.19117717e-02,  3.24664712e-02, -8.16883296e-02,\n",
      "        -1.12132266e-01],\n",
      "       [ 2.78846193e-02, -1.24660179e-01, -5.66323176e-02,\n",
      "         1.23379799e-03,  1.59098074e-01, -1.11517221e-01,\n",
      "        -6.22399412e-02,  1.69498160e-01, -1.40502118e-02,\n",
      "         8.97535589e-03,  4.21541706e-02, -9.35628787e-02,\n",
      "        -6.88068047e-02, -4.04490754e-02,  1.01061955e-01,\n",
      "         1.59155577e-01],\n",
      "       [-2.33511124e-02,  3.27319279e-02,  7.20658377e-02,\n",
      "        -7.49378232e-03,  9.07994956e-02,  3.41395289e-02,\n",
      "        -6.51490642e-03, -4.29031719e-03,  8.41776282e-02,\n",
      "         6.36996850e-02,  3.28066312e-02,  9.88561511e-02,\n",
      "         3.49586308e-02, -6.03614226e-02,  7.84477070e-02,\n",
      "         1.23632085e-02],\n",
      "       [-6.72529563e-02,  7.46822000e-01,  7.23555386e-01,\n",
      "         3.23826581e-01, -4.96252567e-01,  1.76553190e-01,\n",
      "         1.61329404e-01, -9.04957592e-01, -8.87385845e-01,\n",
      "        -7.35679924e-01,  1.19900033e-01, -9.33435738e-01,\n",
      "         8.34034503e-01, -4.59158272e-02,  1.30544677e-01,\n",
      "        -4.33886088e-02],\n",
      "       [-5.78081533e-02,  2.22171083e-01,  5.33182919e-03,\n",
      "         2.33441547e-01, -3.92376393e-01,  1.01360962e-01,\n",
      "         7.35518639e-04, -3.31659764e-01, -3.51418614e-01,\n",
      "        -8.47431645e-02, -2.37697035e-01, -2.19495162e-01,\n",
      "         1.59971148e-01, -9.36138909e-03, -1.42119497e-01,\n",
      "        -3.66754115e-01],\n",
      "       [-1.10211067e-01,  2.26364732e-01,  2.11140245e-01,\n",
      "         1.31356582e-01, -1.64769236e-02, -6.20217845e-02,\n",
      "         2.00696196e-02, -2.02599019e-01, -2.04770491e-01,\n",
      "        -3.39678109e-01,  1.69024795e-01, -2.16167703e-01,\n",
      "         2.67195970e-01, -1.55205401e-02, -6.63675964e-02,\n",
      "         9.41012353e-02],\n",
      "       [ 1.05158938e-02, -1.88819289e-01,  5.21048084e-02,\n",
      "         2.41805073e-02,  2.14619577e-01, -1.11332044e-01,\n",
      "        -3.05184815e-02,  1.53766662e-01, -1.93701804e-01,\n",
      "        -7.29405358e-02,  1.35209456e-01, -1.05683573e-01,\n",
      "        -4.60267290e-02,  2.04661563e-02, -2.12925345e-01,\n",
      "         2.08454177e-01],\n",
      "       [ 2.19108686e-02, -2.93217629e-01,  1.19088970e-01,\n",
      "         4.60455231e-02,  1.80241182e-01, -2.41799906e-01,\n",
      "        -4.06868607e-02,  1.60059422e-01,  2.61733378e-03,\n",
      "         5.40127456e-02,  3.34970355e-01, -3.40139985e-01,\n",
      "        -1.73171461e-01,  1.06042465e-02,  1.54298991e-01,\n",
      "         2.93549836e-01],\n",
      "       [-4.30487841e-02,  4.03155154e-03, -1.98074773e-01,\n",
      "        -5.16910814e-02, -9.21764076e-02,  8.16569552e-02,\n",
      "        -6.99489936e-02,  6.60648942e-02,  1.09552905e-01,\n",
      "         2.23226681e-01, -3.77530128e-01,  3.26685637e-01,\n",
      "        -5.13927452e-02,  2.26221718e-02, -1.48532763e-01,\n",
      "        -2.04245031e-01],\n",
      "       [-7.48011023e-02,  3.79005104e-01,  2.21094608e-01,\n",
      "         3.44163537e-01, -3.53795975e-01,  3.63013536e-01,\n",
      "         1.98568746e-01, -2.32400835e-01, -3.47788215e-01,\n",
      "        -3.90614867e-01, -1.21596061e-01, -1.20271377e-01,\n",
      "         4.34732378e-01,  1.33663304e-02, -3.23228598e-01,\n",
      "        -3.47406209e-01],\n",
      "       [-1.86937258e-01,  2.43676648e-01,  2.38035962e-01,\n",
      "         2.99003363e-01, -2.01219395e-01, -8.74522105e-02,\n",
      "        -2.64917444e-02, -3.36227387e-01, -4.74512041e-01,\n",
      "        -3.60892117e-01,  1.53340966e-01, -5.33713579e-01,\n",
      "         2.51207173e-01, -1.83102896e-03,  6.39538467e-02,\n",
      "         6.25103787e-02],\n",
      "       [-1.72957554e-01,  2.13068902e-01,  2.33817026e-01,\n",
      "         2.92710453e-01, -2.86429137e-01,  1.10402860e-01,\n",
      "         3.35591324e-02, -3.19150269e-01, -4.12569940e-01,\n",
      "        -2.48680457e-01, -7.61722103e-02, -3.85136247e-01,\n",
      "         2.13834137e-01, -4.30881456e-02, -1.79973111e-01,\n",
      "        -1.39045224e-01],\n",
      "       [-1.35656908e-01,  4.34194840e-02,  1.36783153e-01,\n",
      "         1.39267877e-01,  3.56224105e-02, -1.82992523e-03,\n",
      "        -1.24505442e-02, -2.10082576e-01, -1.27507895e-01,\n",
      "         6.28343597e-02,  3.01274564e-03, -2.71709025e-01,\n",
      "         3.59039828e-02, -3.22457477e-02, -3.65464902e-03,\n",
      "        -3.89771797e-02],\n",
      "       [-1.84757952e-02,  3.77816632e-02,  4.44731936e-02,\n",
      "        -3.95311639e-02,  5.66354953e-02,  8.59431177e-02,\n",
      "         8.06191750e-03,  8.53840932e-02, -1.13493301e-01,\n",
      "         1.06328195e-02,  5.21186851e-02,  1.66027788e-02,\n",
      "         1.26408339e-01,  1.27582345e-02, -2.48264503e-02,\n",
      "        -1.28527582e-02],\n",
      "       [-5.80345877e-02,  2.22165048e-01, -1.57495327e-02,\n",
      "        -1.32432893e-01, -1.97867528e-01,  6.74615130e-02,\n",
      "         6.47974061e-03, -2.43271589e-01,  8.72841254e-02,\n",
      "         1.16270527e-01, -1.95393730e-02, -1.13435298e-01,\n",
      "        -7.64500536e-03,  1.64576210e-02,  1.16581507e-01,\n",
      "        -1.89204246e-01],\n",
      "       [-3.25693050e-03,  2.05859825e-01,  3.77612412e-02,\n",
      "         3.81085533e-03,  4.93616536e-02, -3.24165076e-02,\n",
      "        -3.37171294e-02, -9.02676880e-02,  1.02725722e-01,\n",
      "         2.96489865e-01, -1.48414699e-02, -2.71964371e-01,\n",
      "        -6.46840222e-03, -7.03703165e-02, -1.25522479e-01,\n",
      "         7.87028372e-02],\n",
      "       [ 6.16191365e-02, -8.91859755e-02,  2.56249662e-02,\n",
      "        -1.28157675e-01,  1.58694774e-01, -7.20639974e-02,\n",
      "        -1.11357860e-01, -1.72462493e-01,  1.98042765e-01,\n",
      "         1.10974431e-01,  5.03611639e-02, -1.01409338e-01,\n",
      "        -1.61200464e-01, -3.32692638e-02,  2.50579804e-01,\n",
      "        -1.56323254e-01],\n",
      "       [-9.41464156e-02,  3.74699622e-01,  3.06313396e-01,\n",
      "         7.94823766e-02, -2.54617125e-01,  1.57119527e-01,\n",
      "         1.53673455e-01, -1.94142237e-01, -4.54898864e-01,\n",
      "        -3.99794996e-01,  1.26558945e-01, -1.88667282e-01,\n",
      "         2.82764196e-01, -3.42792347e-02, -3.10100079e-01,\n",
      "        -1.86195403e-01],\n",
      "       [-1.27648473e-01,  9.68492180e-02,  5.53733781e-02,\n",
      "        -6.63953274e-02,  1.42373180e-03, -1.05680553e-02,\n",
      "        -8.64381418e-02, -1.77162901e-01, -9.65401530e-02,\n",
      "         7.28321895e-02, -2.13373508e-02, -1.64982170e-01,\n",
      "         7.43786097e-02, -2.05434021e-02,  2.39435479e-01,\n",
      "        -3.83923016e-02],\n",
      "       [-8.33802894e-02,  1.69331267e-01,  2.59104818e-01,\n",
      "         2.27886423e-01, -1.26460031e-01,  6.66478872e-02,\n",
      "         1.72435462e-01, -1.78677157e-01, -3.90538633e-01,\n",
      "        -3.07920814e-01,  9.12974402e-02, -2.14599241e-02,\n",
      "         2.66499758e-01,  1.73070021e-02, -3.21984708e-01,\n",
      "        -9.73930359e-02]], dtype=float32), array([-0.04542498, -0.28485128, -0.24780205,  0.11941509,  0.09337217,\n",
      "       -0.23340693, -0.1655349 ,  0.06949516, -0.02946869,  0.13664013,\n",
      "       -0.04653165, -0.10488178, -0.24731591, -0.02616933, -0.02712381,\n",
      "        0.00257612], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "peso0 = classificador.layers[0].get_weights()\n",
    "print(peso0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(peso0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peso1\n",
    "\n",
    "## Primeiro layers[0] imprime um array (16,16) interligar todos os pessos da primeira camada oculta para a segunda onde ambos tem 16 neuronios.\n",
    "## Depois layers[1] novamente o bias padrão determinado use_bias=True, faz com que o neuronio bias interligue com todos os neuronios da segunda camada oculta(16, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-1.33057669e-01, -5.09967655e-03, -8.41304846e-03,\n",
      "         2.00016499e-02, -6.55798614e-02, -2.35208049e-02,\n",
      "        -1.76493649e-03, -7.38085136e-02, -9.99698997e-04,\n",
      "         3.99493687e-02, -2.21801884e-02, -7.55159557e-02,\n",
      "         1.36915315e-03, -3.41383070e-02, -1.38487043e-02,\n",
      "        -3.79087590e-02],\n",
      "       [ 1.37457669e-01, -2.48144623e-02,  3.21921781e-02,\n",
      "        -1.89448856e-02, -4.19110386e-03, -3.57203074e-02,\n",
      "        -5.97478747e-02,  8.96672532e-02,  1.71468165e-02,\n",
      "         2.67448537e-02, -5.03826328e-02, -2.21978012e-03,\n",
      "         4.65428978e-02, -5.29983197e-04, -1.50927519e-02,\n",
      "        -6.03528693e-03],\n",
      "       [ 4.14321497e-02,  1.52794234e-02,  2.88613569e-02,\n",
      "        -5.02360389e-02, -7.04419985e-02,  2.85575446e-02,\n",
      "        -1.82057824e-02,  3.29437032e-02, -3.35780121e-02,\n",
      "        -3.67607921e-03,  1.19194593e-02, -4.41806614e-02,\n",
      "         1.49071023e-01, -4.71770801e-02, -2.52127256e-02,\n",
      "        -1.44171370e-02],\n",
      "       [-4.91274111e-02, -4.25701030e-02,  1.73429900e-03,\n",
      "         3.92212474e-04, -1.82749987e-01, -1.12628199e-01,\n",
      "         1.68187916e-02,  2.83122212e-01, -1.53576583e-01,\n",
      "         1.63994692e-02, -2.97915060e-02, -1.30271450e-01,\n",
      "         1.15951352e-01,  2.60977703e-03, -1.49615154e-01,\n",
      "        -2.01780396e-03],\n",
      "       [-1.21434726e-01,  2.34685056e-02,  9.82237235e-02,\n",
      "         4.27325489e-03,  1.94870550e-02,  6.66156337e-02,\n",
      "        -4.98308130e-02, -3.08543127e-02,  3.07949688e-02,\n",
      "         3.55253555e-02,  1.26889143e-02,  5.30353710e-02,\n",
      "         3.03016175e-02, -1.94378558e-03,  4.01831307e-02,\n",
      "         1.60686150e-02],\n",
      "       [ 1.67823404e-01, -3.55230570e-02, -6.16902187e-02,\n",
      "        -1.97605100e-02,  2.25963667e-02,  5.79385050e-02,\n",
      "        -6.98332042e-02, -4.31324989e-02,  2.97900550e-02,\n",
      "        -3.33830006e-02, -4.79683988e-02,  3.10515072e-02,\n",
      "         4.83421125e-02, -1.99387446e-02,  2.92757936e-02,\n",
      "        -2.94144219e-03],\n",
      "       [ 1.05535299e-01, -4.18127291e-02,  9.52558964e-03,\n",
      "        -9.64766368e-03, -1.69331636e-02,  8.99473578e-02,\n",
      "        -1.36095323e-02, -4.30823304e-02, -1.14423230e-01,\n",
      "        -5.49923629e-04, -3.31809931e-02, -4.79073310e-03,\n",
      "         1.05519101e-01, -1.63813792e-02, -1.07319228e-01,\n",
      "         5.09305410e-02],\n",
      "       [-6.52548578e-03, -2.76431795e-02, -9.06787887e-02,\n",
      "        -6.81039989e-02,  8.40115771e-02,  4.77944538e-02,\n",
      "        -3.60957608e-02, -2.09995478e-01, -5.00205234e-02,\n",
      "        -3.45530398e-02, -9.08246657e-05, -3.01739499e-02,\n",
      "        -5.16182035e-02, -3.77644040e-02, -8.33882689e-02,\n",
      "        -1.34263793e-02],\n",
      "       [ 9.50595923e-03, -4.75853086e-02, -7.28245378e-02,\n",
      "        -3.31072025e-02, -3.59530263e-02,  5.97721003e-02,\n",
      "        -1.81630161e-02, -1.25418575e-02, -3.89871746e-02,\n",
      "        -4.39285524e-02, -3.71968970e-02,  8.45166668e-03,\n",
      "        -5.63547648e-02, -1.38948241e-03,  3.29465866e-02,\n",
      "        -3.30722556e-02],\n",
      "       [ 2.47436270e-01, -4.04723771e-02, -8.15515127e-03,\n",
      "         8.05505179e-03,  1.59060538e-01, -5.27921133e-02,\n",
      "        -2.23427289e-03, -1.99114919e-01,  5.56574576e-02,\n",
      "        -3.38348523e-02, -3.91587801e-02,  5.67945205e-02,\n",
      "        -5.06712943e-02,  7.35473295e-04,  2.25044833e-03,\n",
      "        -9.26919505e-02],\n",
      "       [-3.40681612e-01, -3.19031961e-02,  6.92470521e-02,\n",
      "         2.27614492e-02, -6.87345564e-02, -5.82026392e-02,\n",
      "        -1.66254900e-02, -2.96671987e-02, -8.77625793e-02,\n",
      "        -4.92428429e-02, -3.67269479e-03, -7.05674589e-02,\n",
      "         5.46368547e-02, -2.04576948e-03, -2.37503331e-02,\n",
      "        -6.78957254e-02],\n",
      "       [ 1.19722605e-01, -1.86531059e-02, -4.53676209e-02,\n",
      "        -5.03549427e-02,  1.23133384e-01, -2.61312611e-02,\n",
      "        -2.00665127e-02, -1.73736766e-01, -3.99361849e-02,\n",
      "        -9.46895033e-03, -2.48021353e-02,  2.45214459e-02,\n",
      "        -7.70365372e-02, -4.68070433e-03,  1.29849948e-02,\n",
      "        -6.58527762e-02],\n",
      "       [ 1.09859854e-01, -4.30382155e-02, -1.12844251e-01,\n",
      "        -7.09604770e-02, -5.91118298e-02, -1.88999232e-02,\n",
      "         1.79404877e-02,  7.79119506e-02, -8.61069933e-03,\n",
      "        -3.25397477e-02, -4.87545244e-02, -1.20377447e-03,\n",
      "         1.18674800e-01, -6.52871281e-02,  2.24415027e-02,\n",
      "        -2.32715216e-02],\n",
      "       [ 2.83403620e-02,  1.07022375e-03,  4.02628109e-02,\n",
      "         1.62265054e-03,  1.40135270e-02, -4.62533161e-03,\n",
      "        -4.87233400e-02,  1.12725385e-02,  3.91900400e-03,\n",
      "        -4.37878631e-02,  1.75353922e-02, -1.94925163e-02,\n",
      "        -6.20269077e-03,  8.74160603e-03, -4.09033196e-03,\n",
      "        -4.68548052e-02],\n",
      "       [-5.44379726e-02, -4.33000587e-02, -6.50868714e-02,\n",
      "        -5.49015142e-02, -1.70903623e-01, -3.70875783e-02,\n",
      "         9.02333185e-02,  2.55359888e-01,  3.29926461e-02,\n",
      "         1.65873654e-02, -6.27401248e-02, -7.76020959e-02,\n",
      "        -5.58239892e-02, -6.06824085e-03,  5.81684187e-02,\n",
      "        -9.07084718e-02],\n",
      "       [-2.19907507e-01, -2.21165419e-02, -7.69034103e-02,\n",
      "        -2.13695504e-02,  3.41572650e-02,  8.18979293e-02,\n",
      "         3.67969344e-03,  5.88444471e-02, -1.01457732e-02,\n",
      "        -1.58876404e-02, -4.83664945e-02,  4.13854010e-02,\n",
      "         5.41791543e-02, -4.79167663e-02, -2.67788749e-02,\n",
      "         3.96775007e-02]], dtype=float32), array([ 0.19192319,  0.        , -0.03161269, -0.03735236,  0.06911053,\n",
      "        0.16505079,  0.00043223, -0.03332859,  0.13003872,  0.        ,\n",
      "       -0.01381277,  0.16435383, -0.2320694 ,  0.00389269,  0.07264266,\n",
      "        0.04103401], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "peso1 = classificador.layers[1].get_weights()\n",
    "print(peso1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(peso1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# peso2\n",
    "\n",
    "## Teremos em layers[0], de tamanho (16,1), nesse array os pesos das ligações da segunda camada oculta para a camada de saída.\n",
    "\n",
    "## Em layers[1] teremos (1, ) novamente o bias padrão que terá um valor pois será apenas ele ligado na camada de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-1.33057669e-01, -5.09967655e-03, -8.41304846e-03,\n",
      "         2.00016499e-02, -6.55798614e-02, -2.35208049e-02,\n",
      "        -1.76493649e-03, -7.38085136e-02, -9.99698997e-04,\n",
      "         3.99493687e-02, -2.21801884e-02, -7.55159557e-02,\n",
      "         1.36915315e-03, -3.41383070e-02, -1.38487043e-02,\n",
      "        -3.79087590e-02],\n",
      "       [ 1.37457669e-01, -2.48144623e-02,  3.21921781e-02,\n",
      "        -1.89448856e-02, -4.19110386e-03, -3.57203074e-02,\n",
      "        -5.97478747e-02,  8.96672532e-02,  1.71468165e-02,\n",
      "         2.67448537e-02, -5.03826328e-02, -2.21978012e-03,\n",
      "         4.65428978e-02, -5.29983197e-04, -1.50927519e-02,\n",
      "        -6.03528693e-03],\n",
      "       [ 4.14321497e-02,  1.52794234e-02,  2.88613569e-02,\n",
      "        -5.02360389e-02, -7.04419985e-02,  2.85575446e-02,\n",
      "        -1.82057824e-02,  3.29437032e-02, -3.35780121e-02,\n",
      "        -3.67607921e-03,  1.19194593e-02, -4.41806614e-02,\n",
      "         1.49071023e-01, -4.71770801e-02, -2.52127256e-02,\n",
      "        -1.44171370e-02],\n",
      "       [-4.91274111e-02, -4.25701030e-02,  1.73429900e-03,\n",
      "         3.92212474e-04, -1.82749987e-01, -1.12628199e-01,\n",
      "         1.68187916e-02,  2.83122212e-01, -1.53576583e-01,\n",
      "         1.63994692e-02, -2.97915060e-02, -1.30271450e-01,\n",
      "         1.15951352e-01,  2.60977703e-03, -1.49615154e-01,\n",
      "        -2.01780396e-03],\n",
      "       [-1.21434726e-01,  2.34685056e-02,  9.82237235e-02,\n",
      "         4.27325489e-03,  1.94870550e-02,  6.66156337e-02,\n",
      "        -4.98308130e-02, -3.08543127e-02,  3.07949688e-02,\n",
      "         3.55253555e-02,  1.26889143e-02,  5.30353710e-02,\n",
      "         3.03016175e-02, -1.94378558e-03,  4.01831307e-02,\n",
      "         1.60686150e-02],\n",
      "       [ 1.67823404e-01, -3.55230570e-02, -6.16902187e-02,\n",
      "        -1.97605100e-02,  2.25963667e-02,  5.79385050e-02,\n",
      "        -6.98332042e-02, -4.31324989e-02,  2.97900550e-02,\n",
      "        -3.33830006e-02, -4.79683988e-02,  3.10515072e-02,\n",
      "         4.83421125e-02, -1.99387446e-02,  2.92757936e-02,\n",
      "        -2.94144219e-03],\n",
      "       [ 1.05535299e-01, -4.18127291e-02,  9.52558964e-03,\n",
      "        -9.64766368e-03, -1.69331636e-02,  8.99473578e-02,\n",
      "        -1.36095323e-02, -4.30823304e-02, -1.14423230e-01,\n",
      "        -5.49923629e-04, -3.31809931e-02, -4.79073310e-03,\n",
      "         1.05519101e-01, -1.63813792e-02, -1.07319228e-01,\n",
      "         5.09305410e-02],\n",
      "       [-6.52548578e-03, -2.76431795e-02, -9.06787887e-02,\n",
      "        -6.81039989e-02,  8.40115771e-02,  4.77944538e-02,\n",
      "        -3.60957608e-02, -2.09995478e-01, -5.00205234e-02,\n",
      "        -3.45530398e-02, -9.08246657e-05, -3.01739499e-02,\n",
      "        -5.16182035e-02, -3.77644040e-02, -8.33882689e-02,\n",
      "        -1.34263793e-02],\n",
      "       [ 9.50595923e-03, -4.75853086e-02, -7.28245378e-02,\n",
      "        -3.31072025e-02, -3.59530263e-02,  5.97721003e-02,\n",
      "        -1.81630161e-02, -1.25418575e-02, -3.89871746e-02,\n",
      "        -4.39285524e-02, -3.71968970e-02,  8.45166668e-03,\n",
      "        -5.63547648e-02, -1.38948241e-03,  3.29465866e-02,\n",
      "        -3.30722556e-02],\n",
      "       [ 2.47436270e-01, -4.04723771e-02, -8.15515127e-03,\n",
      "         8.05505179e-03,  1.59060538e-01, -5.27921133e-02,\n",
      "        -2.23427289e-03, -1.99114919e-01,  5.56574576e-02,\n",
      "        -3.38348523e-02, -3.91587801e-02,  5.67945205e-02,\n",
      "        -5.06712943e-02,  7.35473295e-04,  2.25044833e-03,\n",
      "        -9.26919505e-02],\n",
      "       [-3.40681612e-01, -3.19031961e-02,  6.92470521e-02,\n",
      "         2.27614492e-02, -6.87345564e-02, -5.82026392e-02,\n",
      "        -1.66254900e-02, -2.96671987e-02, -8.77625793e-02,\n",
      "        -4.92428429e-02, -3.67269479e-03, -7.05674589e-02,\n",
      "         5.46368547e-02, -2.04576948e-03, -2.37503331e-02,\n",
      "        -6.78957254e-02],\n",
      "       [ 1.19722605e-01, -1.86531059e-02, -4.53676209e-02,\n",
      "        -5.03549427e-02,  1.23133384e-01, -2.61312611e-02,\n",
      "        -2.00665127e-02, -1.73736766e-01, -3.99361849e-02,\n",
      "        -9.46895033e-03, -2.48021353e-02,  2.45214459e-02,\n",
      "        -7.70365372e-02, -4.68070433e-03,  1.29849948e-02,\n",
      "        -6.58527762e-02],\n",
      "       [ 1.09859854e-01, -4.30382155e-02, -1.12844251e-01,\n",
      "        -7.09604770e-02, -5.91118298e-02, -1.88999232e-02,\n",
      "         1.79404877e-02,  7.79119506e-02, -8.61069933e-03,\n",
      "        -3.25397477e-02, -4.87545244e-02, -1.20377447e-03,\n",
      "         1.18674800e-01, -6.52871281e-02,  2.24415027e-02,\n",
      "        -2.32715216e-02],\n",
      "       [ 2.83403620e-02,  1.07022375e-03,  4.02628109e-02,\n",
      "         1.62265054e-03,  1.40135270e-02, -4.62533161e-03,\n",
      "        -4.87233400e-02,  1.12725385e-02,  3.91900400e-03,\n",
      "        -4.37878631e-02,  1.75353922e-02, -1.94925163e-02,\n",
      "        -6.20269077e-03,  8.74160603e-03, -4.09033196e-03,\n",
      "        -4.68548052e-02],\n",
      "       [-5.44379726e-02, -4.33000587e-02, -6.50868714e-02,\n",
      "        -5.49015142e-02, -1.70903623e-01, -3.70875783e-02,\n",
      "         9.02333185e-02,  2.55359888e-01,  3.29926461e-02,\n",
      "         1.65873654e-02, -6.27401248e-02, -7.76020959e-02,\n",
      "        -5.58239892e-02, -6.06824085e-03,  5.81684187e-02,\n",
      "        -9.07084718e-02],\n",
      "       [-2.19907507e-01, -2.21165419e-02, -7.69034103e-02,\n",
      "        -2.13695504e-02,  3.41572650e-02,  8.18979293e-02,\n",
      "         3.67969344e-03,  5.88444471e-02, -1.01457732e-02,\n",
      "        -1.58876404e-02, -4.83664945e-02,  4.13854010e-02,\n",
      "         5.41791543e-02, -4.79167663e-02, -2.67788749e-02,\n",
      "         3.96775007e-02]], dtype=float32), array([ 0.19192319,  0.        , -0.03161269, -0.03735236,  0.06911053,\n",
      "        0.16505079,  0.00043223, -0.03332859,  0.13003872,  0.        ,\n",
      "       -0.01381277,  0.16435383, -0.2320694 ,  0.00389269,  0.07264266,\n",
      "        0.04103401], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "peso1 = classificador.layers[1].get_weights()\n",
    "print(peso1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(peso1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
